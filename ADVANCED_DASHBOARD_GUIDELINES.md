# 📊 Kibana Dashboard 리스트

## 1️⃣ 실시간 장애 감지 및 대응 (빠른 탐지 & 신속한 대응)
### 목표: 장애 발생 즉시 감지하고 신속히 대응할 수 있는 시스템 구축

### (1) 장애 감지 정확성 검증
- **차트 유형**: Bar Chart
- **X축**: 장애 감지 방식 (ES Watcher, Grafana Alert, 고객 문의 등)
- **Y축**: 감지된 장애 수 (Count)
- **설명**:
  - 장애 감지 시스템이 제대로 작동하는지 분석
  - 고객 문의로 장애를 많이 발견하면 시스템 감지가 부족한 것

### (2) 장애 발생 원인 분석 (Root Cause 파악)
- **차트 유형**: Bar Chart
- **X축**: 장애 원인 유형 (메모리 부족, DB Lock, 네트워크 장애, 서드파티 API 오류 등)
- **Y축**: 발생 횟수 (Count)
- **설명**:
  - 가장 빈번한 장애 유형을 분석하여 사전 대응
  - 원인을 제대로 파악하지 않으면 단순 임시 패치만 반복될 가능성

### (3) 장애 복구 자동화 여부 분석
- **차트 유형**: Bar Chart
- **X축**: 장애 복구 유형 (자동 재시작, 수동 재시작, 임시 패치, 영구 해결)
- **Y축**: 비율 (%)
- **설명**:
  - 장애 감지는 자동이지만 복구는 사람이 수동으로?
  - 자동화할 수 있는 영역을 찾아 운영 비용 절감

### (4) 장애 대응 속도 분석 (MTTD & MTTR)
- **차트 유형**: Line Chart 또는 Bar Chart
- **X축**: 시간 (일/주 단위)
- **Y축**: 평균 탐지 시간(MTTD) / 평균 해결 시간(MTTR)
- **설명**:
  - 장애 감지 후 복구까지 걸리는 시간을 추적
  - 특정 장애 유형에서 MTTR이 길다면 대응 프로세스 개선 필요

### (5) 장애 발생 시점 패턴 분석 (장애 트렌드)
- **차트 유형**: Heatmap
- **X축**: 시간 (0~24시)
- **Y축**: 요일 (월~일)
- **설명**:
  - 특정 시간대에 장애가 집중되면 해당 시간대 운영 강화 필요
  - 트래픽 증가 시간대와 장애 발생 간의 관계 분석

### (6) 외부 API 장애 감지 (3rd Party API 상태 모니터링)
- **차트 유형**: Bar Chart
- **X축**: 외부 API 이름 (PG사 API, 물류 API, 외부몰 API 등)
- **Y축**: 장애 발생 횟수 (Count)
- **설명**:
  - 특정 API에서 장애가 반복적으로 발생하면 백오프 전략 검토
  - 외부 API 장애가 전체 시스템 장애에 미치는 영향 분석
  - [대시보드 가이드 라인](/dashboard/dashboard6.md)

## 2️⃣ 지속적인 성능 개선 및 운영 자동화
### 목표: 서비스의 안정성을 지속적으로 개선하고 운영 자동화 강화

### (7) 성능 저하 감지 (P95, P99 응답 시간 분석)
- **차트 유형**: Bar Chart
- **X축**: Class name (XXQureyRepository, XXFailHandler 등)
- **Y축**: 응답 시간 (ms)
- **설명**:
  - 특정 서비스의 응답 시간이 지속적으로 증가하면 성능 저하 신호
  - 배포 후 성능 변화 분석 가능
  - [대시보드 가이드 라인](/dashboard/dashboard7.md)

### (8) 배포 후 성능 변화 분석 (임팩트 측정)
- **차트 유형**: Bar Chart
- **X축**: 배포 전/후 (배포 전, 1시간 후, 1일 후, 1주일 후)
- **Y축**: 요청 처리량 (TPS) 또는 오류율 (%)
- **설명**:
  - 배포 후 성능이 향상되었는지, 악화되었는지 직관적으로 확인
  - 오류율이 증가했다면 즉각적인 롤백 판단 가능

### (9) API 트래픽 패턴 분석 (부하 분산 최적화)
- **차트 유형**: Bar Chart
- **X축**: 시간 (1시간 단위)
- **Y축**: 요청 수
- **설명**:
  - 특정 시간대에 요청이 집중되면 Auto Scaling 최적화 가능
  - 부하 테스트(TPS 테스트) 결과와 비교하여 운영 안정성 확보

### (10) DB Lock & Slow Query 감지 (트랜잭션 병목 분석)
- **차트 유형**: Line Chart + Table
- **X축**: 시간
- **Y축**: DB Lock 발생 횟수, Slow Query 실행 수
- **설명**:
  - DB 트랜잭션 병목 분석 및 성능 튜닝 필요 여부 파악
  - 특정 서비스에서 DB 문제가 반복되면 Schema 튜닝 고려
  - [대시보드 가이드 라인](/dashboard/dashboard10.md)

### (11) 장애 복구 후 정상화 속도 (Post-Incident Recovery Monitoring)
- **차트 유형**: Line Chart
- **X축**: 장애 발생 이후 경과 시간 (분 단위)
- **Y축**: 트래픽 정상화 비율 (%)
- **설명**:
  - 장애 이후 트래픽 회복 속도가 일정 수준 이하라면 추가 조치 필요
  - Auto Scaling 정책이 적절하게 동작하는지 분석 가능

## 3️⃣ 운영 효율성 개선
### 목표: 로그 및 경고 시스템의 가독성을 높이고 운영 효율성을 극대화

### (12) 로그 및 메트릭스 가독성 평가
- **차트 유형**: Bar Chart
- **X축**: 로그 레벨 (INFO, WARN, ERROR)
- **Y축**: 로그 발생 횟수 (Count)
- **설명**:
  - ERROR 로그가 비정상적으로 많다면 불필요한 노이즈 발생 가능성
  - WARN 로그가 과도하게 많으면 중요한 ERROR 로그를 찾기 어려움

### (13) 배포 후 오류 트렌드 분석 (Rolling Deployment Impact Analysis)
- **차트 유형**: Stacked Bar Chart
- **X축**: 배포 후 경과 시간 (1시간, 3시간, 6시간, 12시간, 24시간)
- **Y축**: 장애 유형별 발생 횟수 (DB 오류, API 오류, Memory Leak 등)
- **설명**:
  - 배포 후 특정 시간대에 장애가 증가하는지 분석
  - 배포 프로세스의 안정성을 높이기 위해 Canary Deployment 검토 가능

